{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Diego Saragoza da Sila\n",
    "\n",
    "Nome: Gabriel Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from cleantext import clean_words, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\user\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\S2\\CDADOS\\CDADOS-P1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('Election.xlsx', 'Treinamento')\n",
    "dados1 = pd.read_excel('Election.xlsx', 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O nosso \"produto\" é as eleições de 2020 dos Estados Unidos da América. Durante nossas classificações, levamos em conta os nomes dos candidatos aos cargos e o contexto da frase do tweet em questão, caso houvesse alguma evidencia sobre votos ou eleições classificavamos este como relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      biden aims big michigan win sanders looks keep...\n",
      "1      wowits almost like berniesanders election http...\n",
      "2      pupiczech2 im trying gather stuff stay in cat ...\n",
      "3      annwilburn7 dnc sorry us think ourselves let e...\n",
      "4      googleexpeuk handyoscar really think needs cal...\n",
      "                             ...                        \n",
      "495    justplainanon pattyangel64 koigi3 disagree who...\n",
      "496    reedgalen corygardner unavailable comment he’s...\n",
      "497    leftistbitch666 houndsofeah thomasisonline gre...\n",
      "498    reptdemocracy slovakia’s recent election igor ...\n",
      "499    realdonaldtrump well learned anything 2016 ele...\n",
      "Length: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "#Tutorial para limpeza de textos para machine learning onde retiramos as duas linhas de código abaixo e seu funcionamento.\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def replaceWords(string):\n",
    "    string = string.lower()\n",
    "    for word in stop_words:\n",
    "        string = string.replace(' ' + word.lower() + ' ', ' ')\n",
    "    string = string.replace('rt', '')\n",
    "    return string\n",
    "\n",
    "#Pegando cada frase dos tweets, aplicando a função clean e transformando os dados em uma Series\n",
    "tweets = []\n",
    "for phrase in dados['Treinamento']:\n",
    "    p = replaceWords(phrase)\n",
    "    p = clean(p, punct = True, extra_spaces = True)\n",
    "    tweets.append(p)\n",
    "            \n",
    "tweets = pd.Series(tweets)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(A|B) = Probabilidade de relevancia da frase dado suas palavras\n",
    "#P(B|A) = Probabilidade das palavras da frase acontecerem dado suas relevancias\n",
    "#P(A)   = Probabilidade de palavras relevantes\n",
    "#P(B)   = Probabilidade da palavra acontecer\n",
    "\n",
    "#Número de frases relevantes\n",
    "r = dados['Relevancia'] == 1\n",
    "relevantes = dados.loc[r, 'Relevancia']\n",
    "\n",
    "#Tabela relativa de relevantes\n",
    "tabela_relevantes = dados.loc[r, 'Treinamento']\n",
    "rel = ''\n",
    "for phrase in tabela_relevantes:\n",
    "    for word in phrase.split():\n",
    "        rel += ' ' + word\n",
    "        \n",
    "rel = clean_words(rel, punct = True, extra_spaces = True)\n",
    "tabela_relativa_relevantes = pd.Series(rel)\n",
    "tabela_relativa_relevantes = tabela_relativa_relevantes.value_counts(True)\n",
    "\n",
    "#Probabilidade de frases relevantes\n",
    "probR = len(relevantes) / len(tweets)\n",
    "\n",
    "#Número de frases não relevantes\n",
    "nr = dados['Relevancia'] == 0\n",
    "naorelevantes = dados.loc[nr, 'Relevancia']\n",
    "\n",
    "#Tabela relativa de não relevantes\n",
    "tabela_nrelevantes = dados.loc[nr, 'Treinamento']\n",
    "nrel = ''\n",
    "for phrase in tabela_nrelevantes:\n",
    "    for word in phrase.split():\n",
    "        nrel += ' ' + word\n",
    "        \n",
    "nrel = clean_words(nrel, punct = True, extra_spaces = True)\n",
    "tabela_relativa_nrelevantes = pd.Series(nrel)\n",
    "tabela_relativa_nrelevantes = tabela_relativa_nrelevantes.value_counts(True)\n",
    "\n",
    "#Probabilidade de frases relevantes\n",
    "probNR = len(naorelevantes) / len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a probabilidade das frases serem relevantes ou não usando o teorema de Bayes\n",
    "probFraseDadoR  = 1\n",
    "probFraseDadoNR = 1\n",
    "tabela_prob_relevante = []\n",
    "tabela_prob_nrelevante = []\n",
    "\n",
    "#Calculando P(B|A) para relevantes\n",
    "for phrase in tweets:\n",
    "    for word in phrase.split():\n",
    "        try:\n",
    "            probFraseDadoR *= tabela_relativa_relevantes[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tabela_prob_relevante.append(probFraseDadoR)\n",
    "    probFraseDadoR = 1\n",
    "\n",
    "#Calculando P(B|A) para não relevantes\n",
    "for phrase in tweets:\n",
    "    for word in phrase.split():\n",
    "        try:\n",
    "            probFraseDadoR *= tabela_relativa_nrelevantes[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tabela_prob_nrelevante.append(probFraseDadoR)\n",
    "    probFraseDadoR = 1\n",
    "\n",
    "#Calculando P(A|B)\n",
    "probRelevanteDadoF = []\n",
    "for value in tabela_prob_relevante:\n",
    "    probRelevanteDadoF.append(value * probR)\n",
    "\n",
    "probNRelevanteDadoF = []\n",
    "for value in tabela_prob_nrelevante:\n",
    "    probNRelevanteDadoF.append(value * probNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for phrase in dados1['Teste']:\n",
    "    p = clean(phrase, punct = True, extra_spaces = True)\n",
    "    p = replaceWords(p)\n",
    "    tweets.append(p)\n",
    "            \n",
    "tweets = pd.Series(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a probabilidade das frases serem relevantes ou não usando o teorema de Bayes\n",
    "probFraseDadoR  = 1\n",
    "probFraseDadoNR = 1\n",
    "tabela_prob_relevante = []\n",
    "tabela_prob_nrelevante = []\n",
    "\n",
    "#Calculando P(B|A) para relevantes\n",
    "for phrase in tweets:\n",
    "    for word in phrase.split():\n",
    "        try:\n",
    "            probFraseDadoR *= tabela_relativa_relevantes[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tabela_prob_relevante.append(probFraseDadoR)\n",
    "    probFraseDadoR = 1\n",
    "\n",
    "#Calculando P(B|A) para não relevantes\n",
    "for phrase in tweets:\n",
    "    for word in phrase.split():\n",
    "        try:\n",
    "            probFraseDadoR *= tabela_relativa_nrelevantes[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tabela_prob_nrelevante.append(probFraseDadoR)\n",
    "    probFraseDadoR = 1\n",
    "\n",
    "#Calculando P(A|B)\n",
    "probRelevanteDadoF = []\n",
    "for value in tabela_prob_relevante:\n",
    "    probRelevanteDadoF.append(value * probR)\n",
    "\n",
    "probNRelevanteDadoF = []\n",
    "for value in tabela_prob_nrelevante:\n",
    "    probNRelevanteDadoF.append(value * probNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O algoritmo acertou 74 de 124 tweets.\n"
     ]
    }
   ],
   "source": [
    "Teste = []\n",
    "relevantes = 0\n",
    "naorelevantes = 0\n",
    "acertos = 0\n",
    "for i in range(len(probRelevanteDadoF)):\n",
    "    if probRelevanteDadoF[i] < probNRelevanteDadoF[i]:\n",
    "        Teste.append(1)\n",
    "        relevantes += 1\n",
    "    else:\n",
    "        Teste.append(0)\n",
    "        naorelevantes += 1\n",
    "    \n",
    "    if Teste[len(Teste) - 1] == dados1.at[i, 'Relevancia']:\n",
    "        acertos += 1\n",
    "        \n",
    "print(\"O algoritmo acertou {0} de {1} tweets.\".format(acertos, len(Teste)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão final\n",
    "O nosso algoritmo acabou acertando cerca de metade dos tweets de teste. Apesar de estarmos usando um método simples de limpeza de texto (retirando algumas palavras irrelevantes, espaços e pontuações) e usando uma classificação binária (relevante ou irrelevante) conseguimos, ao nosso ver, criar um classificador satisfatório com uma complexidade extremamente baixa.\n",
    "Poderiamos ter olhado de maneira mais cuidadosa a limpeza de texto (Guia muito esclarecedor sobre limpeza de textos para machine learning que usamos para pesquisa: https://machinelearningmastery.com/clean-text-machine-learning-python/), a maneira como classificamos nossos tweets, uma base de dados maior que nos ajudaria a refinar o classificador para vários casos distintos (Usando a API do twitter ou outras redes sociais como Facebook ou Instagram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
