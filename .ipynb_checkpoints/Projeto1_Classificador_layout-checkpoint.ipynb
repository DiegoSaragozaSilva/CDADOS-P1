{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Diego Saragoza da Sila\n",
    "\n",
    "Nome: Gabriel Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from cleantext import clean_words, clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\user\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\S2\\CDADOS\\CDADOS-P1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('Election.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O nosso \"produto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      biden aims for big michigan win while sanders ...\n",
      "1      wowits almost like berniesanders has won the e...\n",
      "2      rt pupiczech2 im trying to gather stuff to sta...\n",
      "3      annwilburn7 dnc sorry some of us think for our...\n",
      "4      rt googleexpertuk handyoscar really do think i...\n",
      "                             ...                        \n",
      "495    rt justplainanon pattyangel64 koigi3 disagree ...\n",
      "496    rt reedgalen corygardner is unavailable for co...\n",
      "497    leftistbitch666 houndsofearth thomasisonline g...\n",
      "498    rt reptdemocracy in slovakia’s recent election...\n",
      "499    realdonaldtrump well if we learned anything fr...\n",
      "Length: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Pegando cada frase dos tweets, aplicando a função clean e transformando os dados em uma Series\n",
    "tweets = []\n",
    "for phrase in dados['Treinamento']:\n",
    "    p = clean(phrase, punct = True, extra_spaces = True)\n",
    "    tweets.append(p)\n",
    "            \n",
    "tweets = pd.Series(tweets)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(A|B) = Probabilidade de relevancia da frase dado suas palavras\n",
    "#P(B|A) = Probabilidade das palavras da frase acontecerem dado suas relevancias\n",
    "#P(A)   = Probabilidade de palavras relevantes\n",
    "#P(B)   = Probabilidade da palavra acontecer\n",
    "\n",
    "#Número de frases relevantes\n",
    "r = dados['Relevancia'] == 1\n",
    "relevantes = dados.loc[r, 'Relevancia']\n",
    "\n",
    "#Tabela relativa de relevantes\n",
    "tabela_relevantes = dados.loc[r, 'Treinamento']\n",
    "rel = ''\n",
    "for phrase in tabela_relevantes:\n",
    "    for word in phrase.split():\n",
    "        rel += ' ' + word\n",
    "        \n",
    "rel = clean_words(rel, punct = True, extra_spaces = True)\n",
    "tabela_relativa_relevantes = pd.Series(rel)\n",
    "tabela_relativa_relevantes = tabela_relativa_relevantes.value_counts(True)\n",
    "\n",
    "#Probabilidade de frases relevantes\n",
    "probR = len(relevantes) / len(tweets)\n",
    "\n",
    "#Número de frases não relevantes\n",
    "r = dados['Relevancia'] == 0\n",
    "naorelevantes = dados.loc[r, 'Relevancia']\n",
    "\n",
    "#Tabela relativa de não relevantes\n",
    "tabela_nrelevantes = dados.loc[r, 'Treinamento']\n",
    "nrel = ''\n",
    "for phrase in tabela_nrelevantes:\n",
    "    for word in phrase.split():\n",
    "        nrel += ' ' + word\n",
    "        \n",
    "nrel = clean_words(nrel, punct = True, extra_spaces = True)\n",
    "tabela_relativa_nrelevantes = pd.Series(nrel)\n",
    "tabela_relativa_nrelevantes = tabela_relativa_nrelevantes.value_counts(True)\n",
    "\n",
    "#Probabilidade de frases relevantes\n",
    "probNR = len(naorelevantes) / len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "[1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#Calculando a probabilidade das frases serem relevantes ou não usando o teorema de Bayes\n",
    "probFraseDadoR  = 1\n",
    "probFraseDadoNR = 1\n",
    "tabela_prob_relevante = []\n",
    "tabela_prob_nrelevante = []\n",
    "\n",
    "#Calculando P(B|A) para relevantes\n",
    "for phrase in tweets:\n",
    "    for word in phrase.split():\n",
    "        try:\n",
    "            probFraseDadoR *= tabela_relativa_relevantes[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tabela_prob_relevante.append(probFraseDadoR)\n",
    "    probFraseDadoR = 1\n",
    "\n",
    "#Calculando P(B|A) para não relevantes\n",
    "for phrase in tweets:\n",
    "    for word in phrase.split():\n",
    "        try:\n",
    "            probFraseDadoR *= tabela_relativa_nrelevantes[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tabela_prob_nrelevante.append(probFraseDadoR)\n",
    "    probFraseDadoR = 1\n",
    "\n",
    "#Calculando P(A|B)\n",
    "probRelevanteDadoF = []\n",
    "for value in tabela_prob_relevante:\n",
    "    probRelevanteDadoF.append(value * probR)\n",
    "\n",
    "probNRelevanteDadoF = []\n",
    "for value in tabela_prob_nrelevante:\n",
    "    probNRelevanteDadoF.append(value * probNR)\n",
    "\n",
    "print(len(probRelevanteDadoF))\n",
    "print(len(probNRelevanteDadoF))\n",
    "\n",
    "Teste = []\n",
    "relevantes = 0\n",
    "naorelevantes = 0\n",
    "acertos = 0\n",
    "for i in range(len(probRelevanteDadoF)):\n",
    "    if probRelevanteDadoF[i] < probNRelevanteDadoF[i]:\n",
    "        Teste.append(1)\n",
    "        relevantes += 1\n",
    "    else:\n",
    "        Teste.append(0)\n",
    "        naorelevantes += 1\n",
    "    \n",
    "    #print(Teste[len(Teste) - 1], dados.at[i, 'Relevancia'])\n",
    "    if Teste[len(Teste) - 1] == dados.at[i, 'Relevancia']:\n",
    "        acertos += 1\n",
    "        \n",
    "print(Teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
